name: Apple Silicon Tests

on:
  push:
    branches: [ main ]
    paths:
      - 'ncps/mlx/**'
      - 'ncps/tests/**'
      - '.github/workflows/apple-silicon-tests.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'ncps/mlx/**'
      - 'ncps/tests/**'
      - '.github/workflows/apple-silicon-tests.yml'

jobs:
  test-apple-silicon:
    name: Test on ${{ matrix.device }}
    runs-on: self-hosted
    strategy:
      fail-fast: false
      matrix:
        device: ['M1', 'M1 Pro', 'M1 Max', 'M1 Ultra']
        python-version: ['3.8', '3.9', '3.10']
    
    env:
      DEVICE_TYPE: ${{ matrix.device }}
      PYTHONPATH: ${{ github.workspace }}
      MLX_USE_NEURAL_ENGINE: 1  # Enable Neural Engine
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist
    
    - name: Install MLX
      run: |
        pip install mlx
    
    - name: Verify device type
      run: |
        python -c "
        from ncps.tests.configs.device_configs import detect_device
        config = detect_device()
        assert config.device_type == '${{ matrix.device }}', f'Expected {config.device_type} to be ${{ matrix.device }}'
        "
    
    - name: Run hardware-specific tests
      id: hardware_tests
      run: |
        # Run tests with hardware-specific configurations
        DEVICE_TYPE=${{ matrix.device }} pytest \
          ncps/tests/mlx_benchmarks.py \
          -v \
          --cov=ncps.mlx \
          --cov-report=xml \
          -n auto
    
    - name: Run performance tests
      id: performance_tests
      run: |
        # Run performance benchmarks
        python -m ncps.tests.mlx_benchmarks \
          --device ${{ matrix.device }} \
          --runs 100 \
          --report performance_report.json
    
    - name: Upload test results
      if: always()  # Upload even if tests fail
      uses: actions/upload-artifact@v3
      with:
        name: test-results-${{ matrix.device }}-py${{ matrix.python-version }}
        path: |
          .coverage
          coverage.xml
          performance_report.json
    
    - name: Verify performance requirements
      id: verify_performance
      run: |
        python -c "
        import json
        with open('performance_report.json') as f:
            report = json.load(f)
        from ncps.tests.configs.device_configs import get_device_config
        config = get_device_config('${{ matrix.device }}')
        assert report['summary']['tflops'] >= config.min_tflops, f'TFLOPS below minimum: {report["summary"]["tflops"]} < {config.min_tflops}'
        assert report['summary']['bandwidth'] >= config.min_bandwidth, f'Bandwidth below minimum: {report["summary"]["bandwidth"]} < {config.min_bandwidth}'
        assert report['summary']['peak_memory'] <= config.memory_budget, f'Memory usage above budget: {report["summary"]["peak_memory"]} > {config.memory_budget}'
        "

  summarize-results:
    needs: test-apple-silicon
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Install jq
      run: sudo apt-get install jq
    
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate summary report
      run: |
        echo "# Apple Silicon Test Results" > summary.md
        echo "" >> summary.md
        echo "## Performance Summary" >> summary.md
        echo "" >> summary.md
        echo "| Device | Python | TFLOPS | Bandwidth (GB/s) | Memory (MB) |" >> summary.md
        echo "|--------|--------|---------|-----------------|-------------|" >> summary.md
        for device in M1 "M1 Pro" "M1 Max" "M1 Ultra"; do
          for version in 3.8 3.9 3.10; do
            if [ -f "test-results-${device}-py${version}/performance_report.json" ]; then
              report=$(cat "test-results-${device}-py${version}/performance_report.json")
              tflops=$(echo $report | jq -r '.summary.tflops')
              bandwidth=$(echo $report | jq -r '.summary.bandwidth')
              memory=$(echo $report | jq -r '.summary.peak_memory')
              echo "| $device | $version | $tflops | $bandwidth | $memory |" >> summary.md
            fi
          done
        done
    
    - name: Upload summary report
      uses: actions/upload-artifact@v3
      with:
        name: test-summary
        path: summary.md