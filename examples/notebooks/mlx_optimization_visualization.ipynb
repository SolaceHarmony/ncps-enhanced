{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX Optimization and Visualization Integration\n",
    "\n",
    "This notebook demonstrates how to integrate MLX's optimization tools with our visualization capabilities:\n",
    "- Automatic Differentiation Visualization\n",
    "- Optimizer Analysis\n",
    "- Graph Optimization\n",
    "- Memory Layout Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ncps.mlx import CfC, LTC\n",
    "from ncps.mlx.wirings import Random, NCP, AutoNCP\n",
    "from ncps.mlx.advanced_profiling import MLXProfiler\n",
    "from ncps.mlx.visualization import WiringVisualizer, PerformanceVisualizer, ProfileVisualizer, plot_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Automatic Differentiation Visualization\n",
    "\n",
    "Visualize gradient flow and computation graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_gradient_flow(model, input_data):\n",
    "    \"\"\"Visualize gradient flow through the model.\"\"\"\n",
    "    visualizer = PerformanceVisualizer()\n",
    "    \n",
    "    def loss_fn(model, x):\n",
    "        pred = model(x)\n",
    "        return mx.mean(pred ** 2)\n",
    "    \n",
    "    # Enable gradient recording\n",
    "    mx.enable_grad_recording()\n",
    "    \n",
    "    # Forward and backward pass\n",
    "    loss, grads = mx.value_and_grad(model, loss_fn)(model, input_data)\n",
    "    \n",
    "    # Get gradient statistics\n",
    "    grad_stats = {}\n",
    "    for name, grad in grads.items():\n",
    "        grad_stats[name] = {\n",
    "            'mean': float(mx.mean(mx.abs(grad))),\n",
    "            'std': float(mx.std(grad)),\n",
    "            'max': float(mx.max(mx.abs(grad))),\n",
    "            'sparsity': float(mx.mean(grad == 0))\n",
    "        }\n",
    "    \n",
    "    # Plot gradient statistics\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot mean gradients\n",
    "    plt.subplot(131)\n",
    "    plt.bar(grad_stats.keys(), [s['mean'] for s in grad_stats.values()])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Mean Gradient')\n",
    "    plt.title('Gradient Magnitudes')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot gradient distributions\n",
    "    plt.subplot(132)\n",
    "    for name, grad in grads.items():\n",
    "        plt.hist(mx.array(grad).reshape(-1), bins=50, alpha=0.5, label=name)\n",
    "    plt.xlabel('Gradient Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Gradient Distributions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot gradient sparsity\n",
    "    plt.subplot(133)\n",
    "    plt.bar(grad_stats.keys(), [s['sparsity'] for s in grad_stats.values()])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Sparsity')\n",
    "    plt.title('Gradient Sparsity')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return grad_stats\n",
    "\n",
    "# Create model and data\n",
    "wiring = Random(units=100, sparsity_level=0.5)\n",
    "model = CfC(wiring=wiring)\n",
    "x = mx.random.normal((32, 10, 8))\n",
    "\n",
    "# Visualize gradient flow\n",
    "grad_stats = visualize_gradient_flow(model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimizer Analysis\n",
    "\n",
    "Compare and visualize different optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compare_optimizers(model, X, y, optimizers, num_epochs=50):\n",
    "    \"\"\"Compare different optimizers.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name, optimizer in optimizers.items():\n",
    "        print(f\"\\nTraining with {name}...\")\n",
    "        \n",
    "        # Reset model\n",
    "        model.reset_parameters()\n",
    "        \n",
    "        # Create visualizer\n",
    "        visualizer = PerformanceVisualizer()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            def loss_fn(model, x, y):\n",
    "                pred = model(x)\n",
    "                return mx.mean((pred - y) ** 2)\n",
    "            \n",
    "            # Forward and backward pass\n",
    "            loss, grads = mx.value_and_grad(model, loss_fn)(model, X, y)\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.update(model, grads)\n",
    "            \n",
    "            # Record metrics\n",
    "            visualizer.add_metrics(\n",
    "                loss=float(loss),\n",
    "                time=epoch\n",
    "            )\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}: Loss = {float(loss):.4f}\")\n",
    "        \n",
    "        results[name] = visualizer.history\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(results, metrics=['loss'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create model and data\n",
    "wiring = Random(units=100, sparsity_level=0.5)\n",
    "model = CfC(wiring=wiring)\n",
    "X = mx.random.normal((1000, 10, 8))\n",
    "y = mx.random.normal((1000, 10, 1))\n",
    "\n",
    "# Define optimizers\n",
    "optimizers = {\n",
    "    'SGD': optim.SGD(learning_rate=0.01),\n",
    "    'Adam': optim.Adam(learning_rate=0.001),\n",
    "    'AdamW': optim.AdamW(learning_rate=0.001, weight_decay=0.01),\n",
    "    'Lion': optim.Lion(learning_rate=0.0001)\n",
    "}\n",
    "\n",
    "# Compare optimizers\n",
    "optimizer_results = compare_optimizers(model, X, y, optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Optimization\n",
    "\n",
    "Visualize computation graph optimizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_graph_optimization(model, input_data):\n",
    "    \"\"\"Analyze computation graph optimization.\"\"\"\n",
    "    profiler = MLXProfiler(model)\n",
    "    \n",
    "    # Profile without optimization\n",
    "    mx.disable_compile()\n",
    "    unopt_stats = profiler.profile_compute(\n",
    "        batch_size=input_data.shape[0],\n",
    "        seq_length=input_data.shape[1],\n",
    "        num_runs=100\n",
    "    )\n",
    "    \n",
    "    # Profile with optimization\n",
    "    mx.enable_compile()\n",
    "    opt_stats = profiler.profile_compute(\n",
    "        batch_size=input_data.shape[0],\n",
    "        seq_length=input_data.shape[1],\n",
    "        num_runs=100\n",
    "    )\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot execution time\n",
    "    plt.subplot(131)\n",
    "    plt.bar(['Unoptimized', 'Optimized'],\n",
    "            [unopt_stats['time_mean']*1000, opt_stats['time_mean']*1000])\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('Execution Time')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot TFLOPS\n",
    "    plt.subplot(132)\n",
    "    plt.bar(['Unoptimized', 'Optimized'],\n",
    "            [unopt_stats['tflops'], opt_stats['tflops']])\n",
    "    plt.ylabel('TFLOPS')\n",
    "    plt.title('Compute Efficiency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot speedup\n",
    "    plt.subplot(133)\n",
    "    speedup = unopt_stats['time_mean'] / opt_stats['time_mean']\n",
    "    plt.bar(['Speedup'], [speedup])\n",
    "    plt.ylabel('Factor')\n",
    "    plt.title('Optimization Speedup')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'unoptimized': unopt_stats,\n",
    "        'optimized': opt_stats,\n",
    "        'speedup': speedup\n",
    "    }\n",
    "\n",
    "# Analyze graph optimization\n",
    "optimization_results = analyze_graph_optimization(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory Layout Optimization\n",
    "\n",
    "Analyze memory layout optimizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_memory_layout(model, input_data):\n",
    "    \"\"\"Analyze memory layout optimization.\"\"\"\n",
    "    profiler = MLXProfiler(model)\n",
    "    \n",
    "    # Profile different batch sizes\n",
    "    batch_sizes = [1, 16, 32, 64, 128]\n",
    "    results = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        # Reshape input\n",
    "        x = mx.reshape(input_data[:batch_size], (batch_size, -1, input_data.shape[-1]))\n",
    "        \n",
    "        # Profile memory\n",
    "        memory_stats = profiler.profile_memory(\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Profile stream\n",
    "        stream_stats = profiler.profile_stream(\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'batch_size': batch_size,\n",
    "            'peak_memory': memory_stats['peak_usage'],\n",
    "            'memory_time': stream_stats['memory_time'],\n",
    "            'kernel_time': stream_stats['kernel_time']\n",
    "        })\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot memory usage\n",
    "    plt.subplot(131)\n",
    "    plt.plot([r['batch_size'] for r in results],\n",
    "             [r['peak_memory'] for r in results],\n",
    "             marker='o')\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.ylabel('Memory (MB)')\n",
    "    plt.title('Peak Memory Usage')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot memory bandwidth\n",
    "    plt.subplot(132)\n",
    "    bandwidth = [r['peak_memory']/r['memory_time'] for r in results]\n",
    "    plt.plot([r['batch_size'] for r in results],\n",
    "             bandwidth,\n",
    "             marker='o')\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.ylabel('GB/s')\n",
    "    plt.title('Memory Bandwidth')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot compute/memory ratio\n",
    "    plt.subplot(133)\n",
    "    ratio = [r['kernel_time']/r['memory_time'] for r in results]\n",
    "    plt.plot([r['batch_size'] for r in results],\n",
    "             ratio,\n",
    "             marker='o')\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.ylabel('Ratio')\n",
    "    plt.title('Compute/Memory Ratio')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze memory layout\n",
    "memory_results = analyze_memory_layout(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Insights\n",
    "\n",
    "Based on our analysis:\n",
    "\n",
    "1. **Gradient Flow**\n",
    "   - Gradient magnitudes vary by layer\n",
    "   - Some layers show high sparsity\n",
    "   - Distribution shapes indicate training stability\n",
    "\n",
    "2. **Optimizer Performance**\n",
    "   - Adam shows fastest convergence\n",
    "   - AdamW helps with regularization\n",
    "   - Lion uses less memory\n",
    "\n",
    "3. **Graph Optimization**\n",
    "   - Significant speedup from compilation\n",
    "   - Better TFLOPS with optimization\n",
    "   - Memory access patterns improved\n",
    "\n",
    "4. **Memory Layout**\n",
    "   - Memory scales with batch size\n",
    "   - Bandwidth utilization improves\n",
    "   - Compute/memory balance important\n",
    "\n",
    "Recommendations:\n",
    "- Monitor gradient flow\n",
    "- Choose optimizer based on task\n",
    "- Enable graph optimization\n",
    "- Optimize memory layout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
