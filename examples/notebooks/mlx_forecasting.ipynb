{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Liquid Neural Networks\n",
    "\n",
    "This notebook demonstrates how to use liquid neural networks (CfC and LTC) for time series forecasting. We'll cover:\n",
    "- Single-step and multi-step forecasting\n",
    "- Handling variable time steps\n",
    "- Incorporating multiple features\n",
    "- Uncertainty estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ncps.mlx import CfC, LTC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forecasting Models\n",
    "\n",
    "We'll implement models for both single-step and multi-step forecasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiquidForecaster(nn.Module):\n",
    "    \"\"\"Time series forecasting model using liquid neurons.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_steps=1, cell_type='cfc'):\n",
    "        super().__init__()\n",
    "        self.output_steps = output_steps\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.feature_extractor = CfC if cell_type == 'cfc' else LTC\n",
    "        self.feature_extractor = self.feature_extractor(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            backbone_units=64,\n",
    "            backbone_layers=2,\n",
    "            return_sequences=True\n",
    "        )\n",
    "        \n",
    "        # Prediction heads\n",
    "        self.forecast_head = nn.Linear(hidden_size, input_size * output_steps)\n",
    "        self.uncertainty_head = nn.Linear(hidden_size, input_size * output_steps)\n",
    "    \n",
    "    def __call__(self, x, time_delta=None):\n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x, time_delta=time_delta)\n",
    "        # Use last state for prediction\n",
    "        last_features = features[:, -1]\n",
    "        \n",
    "        # Generate predictions and uncertainty estimates\n",
    "        forecast = self.forecast_head(last_features)\n",
    "        uncertainty = nn.softplus(self.uncertainty_head(last_features))\n",
    "        \n",
    "        # Reshape for multi-step predictions\n",
    "        batch_size = x.shape[0]\n",
    "        forecast = forecast.reshape(batch_size, self.output_steps, -1)\n",
    "        uncertainty = uncertainty.reshape(batch_size, self.output_steps, -1)\n",
    "        \n",
    "        return forecast, uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data\n",
    "\n",
    "We'll create synthetic time series data with multiple seasonal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(n_samples=1000, seq_length=100, n_features=3):\n",
    "    \"\"\"Generate synthetic time series with multiple components.\"\"\"\n",
    "    # Time points\n",
    "    t = np.linspace(0, 8*np.pi, seq_length)\n",
    "    \n",
    "    # Generate data\n",
    "    data = np.zeros((n_samples, seq_length, n_features))\n",
    "    targets = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Generate components with different frequencies\n",
    "        trend = 0.1 * t\n",
    "        seasonal1 = 2 * np.sin(t + np.random.rand() * np.pi)\n",
    "        seasonal2 = np.sin(2*t + np.random.rand() * np.pi)\n",
    "        noise = 0.2 * np.random.randn(seq_length)\n",
    "        \n",
    "        # Combine components\n",
    "        base_signal = trend + seasonal1 + seasonal2 + noise\n",
    "        \n",
    "        # Create multiple features\n",
    "        for j in range(n_features):\n",
    "            phase_shift = j * np.pi / 4\n",
    "            amplitude = 1.0 + 0.2 * j\n",
    "            data[i, :, j] = amplitude * base_signal + np.sin(t + phase_shift)\n",
    "        \n",
    "        # Generate target (next value)\n",
    "        t_next = t[-1] + (t[1] - t[0])\n",
    "        for j in range(n_features):\n",
    "            phase_shift = j * np.pi / 4\n",
    "            amplitude = 1.0 + 0.2 * j\n",
    "            trend_next = 0.1 * t_next\n",
    "            seasonal1_next = 2 * np.sin(t_next + np.random.rand() * np.pi)\n",
    "            seasonal2_next = np.sin(2*t_next + np.random.rand() * np.pi)\n",
    "            targets[i, j] = amplitude * (trend_next + seasonal1_next + seasonal2_next)\n",
    "    \n",
    "    # Generate variable time steps\n",
    "    time_delta = np.ones((n_samples, seq_length, 1))\n",
    "    for i in range(n_samples):\n",
    "        time_delta[i] += 0.1 * np.random.randn(seq_length, 1)\n",
    "    \n",
    "    return mx.array(data), mx.array(targets), mx.array(time_delta)\n",
    "\n",
    "# Generate data\n",
    "X, y, time_delta = generate_time_series()\n",
    "\n",
    "# Plot example sequence\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(X[0, :, i], label=f'Feature {i+1}')\n",
    "    plt.scatter(len(X[0]), y[0, i], c='r', label='Target')\n",
    "    plt.title(f'Feature {i+1} with Target')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forecaster(model, X, y, time_delta, n_epochs=100, batch_size=32):\n",
    "    \"\"\"Train the forecasting model.\"\"\"\n",
    "    optimizer = nn.Adam(learning_rate=0.001)\n",
    "    \n",
    "    def loss_fn(model, x, y, dt):\n",
    "        # Get predictions and uncertainty estimates\n",
    "        pred, uncertainty = model(x, time_delta=dt)\n",
    "        \n",
    "        # Negative log likelihood loss with uncertainty\n",
    "        squared_error = (pred[:, 0] - y) ** 2  # Use first prediction step\n",
    "        uncertainty_term = mx.log(uncertainty[:, 0] + 1e-6)\n",
    "        loss = mx.mean(squared_error / (2 * uncertainty[:, 0] + 1e-6) + uncertainty_term)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "    n_samples = X.shape[0]\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        # Shuffle data\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        \n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            batch_X = X[batch_idx]\n",
    "            batch_y = y[batch_idx]\n",
    "            batch_dt = time_delta[batch_idx]\n",
    "            \n",
    "            loss, grads = loss_and_grad_fn(model, batch_X, batch_y, batch_dt)\n",
    "            optimizer.update(model, grads)\n",
    "            epoch_losses.append(float(loss))\n",
    "        \n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Train CfC model\n",
    "print(\"Training CfC forecaster...\")\n",
    "cfc_model = LiquidForecaster(input_size=3, hidden_size=32, output_steps=5, cell_type='cfc')\n",
    "cfc_losses = train_forecaster(cfc_model, X, y, time_delta)\n",
    "\n",
    "# Train LTC model\n",
    "print(\"\\nTraining LTC forecaster...\")\n",
    "ltc_model = LiquidForecaster(input_size=3, hidden_size=32, output_steps=5, cell_type='ltc')\n",
    "ltc_losses = train_forecaster(ltc_model, X, y, time_delta)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cfc_losses, label='CfC')\n",
    "plt.plot(ltc_losses, label='LTC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts(model, X, y, time_delta):\n",
    "    \"\"\"Evaluate forecasting performance.\"\"\"\n",
    "    # Get predictions and uncertainty\n",
    "    predictions, uncertainties = model(X, time_delta=time_delta)\n",
    "    \n",
    "    # Compute metrics\n",
    "    mse = mx.mean((predictions[:, 0] - y) ** 2)\n",
    "    mae = mx.mean(mx.abs(predictions[:, 0] - y))\n",
    "    \n",
    "    # Compute calibration (percentage of true values within uncertainty bounds)\n",
    "    std = mx.sqrt(uncertainties[:, 0])\n",
    "    lower_bound = predictions[:, 0] - 2 * std\n",
    "    upper_bound = predictions[:, 0] + 2 * std\n",
    "    calibration = mx.mean((y >= lower_bound) & (y <= upper_bound))\n",
    "    \n",
    "    return {\n",
    "        'mse': float(mse),\n",
    "        'mae': float(mae),\n",
    "        'calibration': float(calibration),\n",
    "        'predictions': predictions,\n",
    "        'uncertainties': uncertainties\n",
    "    }\n",
    "\n",
    "# Evaluate models\n",
    "cfc_results = evaluate_forecasts(cfc_model, X, y, time_delta)\n",
    "ltc_results = evaluate_forecasts(ltc_model, X, y, time_delta)\n",
    "\n",
    "print(\"CfC Results:\")\n",
    "print(f\"MSE: {cfc_results['mse']:.4f}\")\n",
    "print(f\"MAE: {cfc_results['mae']:.4f}\")\n",
    "print(f\"Calibration: {cfc_results['calibration']:.4f}\")\n",
    "\n",
    "print(\"\\nLTC Results:\")\n",
    "print(f\"MSE: {ltc_results['mse']:.4f}\")\n",
    "print(f\"MAE: {ltc_results['mae']:.4f}\")\n",
    "print(f\"Calibration: {ltc_results['calibration']:.4f}\")\n",
    "\n",
    "# Plot example forecasts\n",
    "def plot_forecast(model_name, predictions, uncertainties, true_values, feature_idx=0):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot predictions with uncertainty\n",
    "    steps = np.arange(predictions.shape[1])\n",
    "    mean = predictions[0, :, feature_idx]\n",
    "    std = mx.sqrt(uncertainties[0, :, feature_idx])\n",
    "    \n",
    "    plt.plot(steps, mean, 'b-', label='Prediction')\n",
    "    plt.fill_between(steps, \n",
    "                     mean - 2*std,\n",
    "                     mean + 2*std,\n",
    "                     color='b', alpha=0.2,\n",
    "                     label='95% Confidence')\n",
    "    \n",
    "    # Plot true value\n",
    "    plt.scatter(0, true_values[0, feature_idx], \n",
    "               c='r', label='True Value')\n",
    "    \n",
    "    plt.title(f'{model_name} Multi-step Forecast (Feature {feature_idx+1})')\n",
    "    plt.xlabel('Steps Ahead')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot example forecasts for each model\n",
    "plot_forecast('CfC', cfc_results['predictions'], \n",
    "             cfc_results['uncertainties'], y)\n",
    "plot_forecast('LTC', ltc_results['predictions'], \n",
    "             ltc_results['uncertainties'], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Stock Price Forecasting\n",
    "\n",
    "Let's apply our models to stock price prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stock_data(n_days=1000):\n",
    "    \"\"\"Generate realistic stock market data.\"\"\"\n",
    "    # Generate dates\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_days)]\n",
    "    dates = dates[::-1]\n",
    "    \n",
    "    # Initial price\n",
    "    price = 100.0\n",
    "    prices = [price]\n",
    "    volumes = []\n",
    "    volatilities = []\n",
    "    \n",
    "    # Generate daily data\n",
    "    for i in range(1, n_days):\n",
    "        # Price movement\n",
    "        daily_return = np.random.normal(0.0001, 0.02)\n",
    "        price *= (1 + daily_return)\n",
    "        prices.append(price)\n",
    "        \n",
    "        # Trading volume (higher on volatile days)\n",
    "        base_volume = 1000000\n",
    "        volume = base_volume * (1 + abs(daily_return) * 10)\n",
    "        volumes.append(volume)\n",
    "        \n",
    "        # Volatility\n",
    "        volatility = abs(daily_return)\n",
    "        volatilities.append(volatility)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'price': prices,\n",
    "        'volume': volumes,\n",
    "        'volatility': volatilities\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate stock data\n",
    "stock_data = generate_stock_data()\n",
    "\n",
    "# Prepare sequences\n",
    "def prepare_sequences(data, seq_length=50):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[['price', 'volume', 'volatility']])\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(scaled_data) - seq_length):\n",
    "        sequences.append(scaled_data[i:i+seq_length])\n",
    "        targets.append(scaled_data[i+seq_length, 0])  # Predict next price\n",
    "    \n",
    "    return np.array(sequences), np.array(targets), scaler\n",
    "\n",
    "# Prepare data\n",
    "X_stock, y_stock, scaler = prepare_sequences(stock_data)\n",
    "time_delta_stock = np.ones((X_stock.shape[0], X_stock.shape[1], 1))\n",
    "\n",
    "# Convert to MLX arrays\n",
    "X_stock = mx.array(X_stock)\n",
    "y_stock = mx.array(y_stock)\n",
    "time_delta_stock = mx.array(time_delta_stock)\n",
    "\n",
    "# Train stock forecaster\n",
    "stock_model = LiquidForecaster(input_size=3, hidden_size=64, output_steps=5, cell_type='cfc')\n",
    "stock_losses = train_forecaster(stock_model, X_stock, y_stock, time_delta_stock)\n",
    "\n",
    "# Evaluate stock predictions\n",
    "stock_results = evaluate_forecasts(stock_model, X_stock, y_stock, time_delta_stock)\n",
    "\n",
    "print(\"Stock Forecasting Results:\")\n",
    "print(f\"MSE: {stock_results['mse']:.4f}\")\n",
    "print(f\"MAE: {stock_results['mae']:.4f}\")\n",
    "print(f\"Calibration: {stock_results['calibration']:.4f}\")\n",
    "\n",
    "# Plot stock predictions\n",
    "plot_forecast('Stock Price', stock_results['predictions'],\n",
    "             stock_results['uncertainties'], y_stock.reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
