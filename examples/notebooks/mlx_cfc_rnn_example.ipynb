{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Neural Circuit Policies with MLX\n",
    "\n",
    "This notebook demonstrates advanced features of the CfC (Closed-form Continuous-time) implementation in MLX, focusing on the CfCRNN for complex sequence processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "from ncps.mlx import CfCRNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bidirectional Sequence Model\n",
    "\n",
    "We'll create a model that processes sequences in both directions using CfCRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = CfCRNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            backbone_units=64,\n",
    "            backbone_layers=2\n",
    "        )\n",
    "        # Since the RNN is bidirectional, output dimension is 2*hidden_size\n",
    "        self.output_layer = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def __call__(self, x, time_delta=None):\n",
    "        # Get sequence output and final states\n",
    "        sequence_output, states = self.rnn(x, time_delta=time_delta)\n",
    "        # Use the final sequence output for prediction\n",
    "        final_output = self.output_layer(sequence_output[:, -1])\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Complex Sequence Data\n",
    "\n",
    "We'll create a more complex sequence prediction task that involves multiple sinusoidal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complex_data(batch_size, seq_length):\n",
    "    t = np.linspace(0, 8*np.pi, seq_length)\n",
    "    \n",
    "    # Create sequences with multiple frequency components\n",
    "    x1 = np.sin(t)\n",
    "    x2 = 0.5 * np.sin(2*t)\n",
    "    x3 = 0.25 * np.sin(4*t)\n",
    "    x = x1 + x2 + x3\n",
    "    \n",
    "    # Create batches with 2D input (two features)\n",
    "    X = np.zeros((batch_size, seq_length-1, 2))\n",
    "    y = np.zeros((batch_size, 2))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        start_idx = np.random.randint(0, len(x)-seq_length)\n",
    "        # First feature is the signal\n",
    "        X[i, :, 0] = x[start_idx:start_idx+seq_length-1]\n",
    "        # Second feature is the derivative\n",
    "        X[i, :, 1] = np.gradient(x[start_idx:start_idx+seq_length-1])\n",
    "        # Target is next value and its derivative\n",
    "        y[i, 0] = x[start_idx+seq_length-1]\n",
    "        y[i, 1] = np.gradient(x)[start_idx+seq_length-1]\n",
    "    \n",
    "    return mx.array(X), mx.array(y)\n",
    "\n",
    "# Generate example data\n",
    "X, y = generate_complex_data(batch_size=1, seq_length=100)\n",
    "\n",
    "# Plot example sequence\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(X[0, :, 0], label='Signal')\n",
    "plt.plot(X[0, :, 1], label='Derivative')\n",
    "plt.legend()\n",
    "plt.title('Example Training Sequence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model with Time-Aware Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and optimizer\n",
    "model = BidirectionalModel(input_size=2, hidden_size=32, output_size=2)\n",
    "\n",
    "def loss_fn(model, X, y, time_delta=None):\n",
    "    pred = model(X, time_delta=time_delta)\n",
    "    return mx.mean((pred - y) ** 2)\n",
    "\n",
    "# Get gradients function\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 32\n",
    "seq_length = 50\n",
    "n_epochs = 100\n",
    "\n",
    "optimizer = nn.Adam(learning_rate=0.001)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = generate_complex_data(batch_size, seq_length)\n",
    "    \n",
    "    # Create variable time deltas to demonstrate time-aware processing\n",
    "    time_delta = 1.0 + 0.1 * mx.random.uniform((batch_size, seq_length-1))\n",
    "    \n",
    "    # Compute loss and gradients\n",
    "    loss, grads = loss_and_grad_fn(model, X, y, time_delta)\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.update(model, grads)\n",
    "    \n",
    "    losses.append(float(loss))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Plot training progress\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test sequence\n",
    "X_test, y_test = generate_complex_data(batch_size=1, seq_length=200)\n",
    "time_delta_test = mx.ones((1, 199))  # Use constant time steps for testing\n",
    "\n",
    "# Get predictions\n",
    "pred = model(X_test, time_delta=time_delta_test)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(X_test[0, :, 0], label='Input Signal')\n",
    "plt.plot(len(X_test[0]), float(pred[0, 0]), 'ro', label='Predicted Signal')\n",
    "plt.plot(len(X_test[0]), float(y_test[0, 0]), 'go', label='True Signal')\n",
    "plt.legend()\n",
    "plt.title('Signal Prediction')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(X_test[0, :, 1], label='Input Derivative')\n",
    "plt.plot(len(X_test[0]), float(pred[0, 1]), 'ro', label='Predicted Derivative')\n",
    "plt.plot(len(X_test[0]), float(y_test[0, 1]), 'go', label='True Derivative')\n",
    "plt.legend()\n",
    "plt.title('Derivative Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
