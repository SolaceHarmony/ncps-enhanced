{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Circuit Policy Wiring Patterns\n",
    "\n",
    "This notebook demonstrates how to use different wiring patterns with liquid neural networks in MLX. We'll cover:\n",
    "- Fully connected networks\n",
    "- Random sparse networks\n",
    "- Neural Circuit Policy (NCP) architectures\n",
    "- Custom wiring patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ncps.mlx import CfC, LTC\n",
    "from ncps.mlx.wirings import Wiring, FullyConnected, Random, NCP, AutoNCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fully Connected Networks\n",
    "\n",
    "Let's start with a fully connected network where every neuron is connected to every other neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create fully connected wiring\n",
    "wiring = FullyConnected(\n",
    "    units=32,\n",
    "    output_dim=10,\n",
    "    self_connections=True\n",
    ")\n",
    "\n",
    "# Create CfC model with this wiring\n",
    "model = CfC(\n",
    "    wiring=wiring,\n",
    "    activation=\"tanh\",\n",
    "    backbone_units=[64],\n",
    "    backbone_layers=1\n",
    ")\n",
    "\n",
    "# Generate sample data\n",
    "batch_size = 16\n",
    "seq_length = 20\n",
    "input_dim = 8\n",
    "x = mx.random.normal((batch_size, seq_length, input_dim))\n",
    "\n",
    "# Process data\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Sparse Networks\n",
    "\n",
    "Random sparse networks have fewer connections, which can improve efficiency and generalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create random sparse wiring\n",
    "wiring = Random(\n",
    "    units=32,\n",
    "    output_dim=10,\n",
    "    sparsity_level=0.5  # 50% of possible connections\n",
    ")\n",
    "\n",
    "# Create LTC model with this wiring\n",
    "model = LTC(\n",
    "    wiring=wiring,\n",
    "    activation=\"tanh\",\n",
    "    backbone_units=[64],\n",
    "    backbone_layers=1\n",
    ")\n",
    "\n",
    "# Process data\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Number of synapses: {wiring.synapse_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Circuit Policy (NCP)\n",
    "\n",
    "NCPs use a structured architecture with distinct neuron types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create NCP wiring\n",
    "wiring = NCP(\n",
    "    inter_neurons=16,\n",
    "    command_neurons=8,\n",
    "    motor_neurons=4,\n",
    "    sensory_fanout=4,\n",
    "    inter_fanout=4,\n",
    "    recurrent_command_synapses=3,\n",
    "    motor_fanin=4\n",
    ")\n",
    "\n",
    "# Create CfC model with NCP wiring\n",
    "model = CfC(\n",
    "    wiring=wiring,\n",
    "    activation=\"tanh\",\n",
    "    backbone_units=[64],\n",
    "    backbone_layers=1\n",
    ")\n",
    "\n",
    "# Process data\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Print neuron types\n",
    "for i in range(wiring.units):\n",
    "    print(f\"Neuron {i}: {wiring.get_type_of_neuron(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatic NCP\n",
    "\n",
    "AutoNCP simplifies NCP creation with automatic architecture selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create AutoNCP wiring\n",
    "wiring = AutoNCP(\n",
    "    units=32,\n",
    "    output_size=4,\n",
    "    sparsity_level=0.5\n",
    ")\n",
    "\n",
    "# Create model with AutoNCP wiring\n",
    "model = CfC(\n",
    "    wiring=wiring,\n",
    "    activation=\"tanh\",\n",
    "    backbone_units=[64],\n",
    "    backbone_layers=1\n",
    ")\n",
    "\n",
    "# Process data\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Wiring\n",
    "\n",
    "You can create custom wiring patterns by subclassing the Wiring class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class LayeredWiring(Wiring):\n",
    "    \"\"\"Custom wiring with layered connectivity.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, connections_per_layer=2):\n",
    "        total_units = sum(layer_sizes)\n",
    "        super().__init__(total_units)\n",
    "        \n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.connections_per_layer = connections_per_layer\n",
    "        self.set_output_dim(layer_sizes[-1])\n",
    "        \n",
    "        # Connect layers\n",
    "        start_idx = 0\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            current_size = layer_sizes[i]\n",
    "            next_size = layer_sizes[i + 1]\n",
    "            \n",
    "            # Connect each neuron to n neurons in next layer\n",
    "            for j in range(current_size):\n",
    "                current_idx = start_idx + j\n",
    "                next_indices = np.random.choice(\n",
    "                    range(start_idx + current_size, start_idx + current_size + next_size),\n",
    "                    size=connections_per_layer,\n",
    "                    replace=False\n",
    "                )\n",
    "                \n",
    "                for next_idx in next_indices:\n",
    "                    self.add_synapse(current_idx, next_idx, 1)\n",
    "            \n",
    "            start_idx += current_size\n",
    "\n",
    "# Create custom layered wiring\n",
    "wiring = LayeredWiring(\n",
    "    layer_sizes=[16, 8, 4],\n",
    "    connections_per_layer=2\n",
    ")\n",
    "\n",
    "# Create model with custom wiring\n",
    "model = CfC(\n",
    "    wiring=wiring,\n",
    "    activation=\"tanh\",\n",
    "    backbone_units=[64],\n",
    "    backbone_layers=1\n",
    ")\n",
    "\n",
    "# Process data\n",
    "output = model(x)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Number of synapses: {wiring.synapse_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training with Different Wirings\n",
    "\n",
    "Let's compare how different wiring patterns perform on a simple task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_sine_data(samples=1000, seq_length=50):\n",
    "    \"\"\"Create sine wave prediction data.\"\"\"\n",
    "    t = np.linspace(0, 4*np.pi, seq_length)\n",
    "    X = np.zeros((samples, seq_length, 1))\n",
    "    y = np.zeros((samples, seq_length, 1))\n",
    "    \n",
    "    for i in range(samples):\n",
    "        phase = np.random.rand() * 2 * np.pi\n",
    "        freq = 1.0 + 0.1 * np.random.randn()\n",
    "        X[i, :, 0] = np.sin(freq * t + phase)\n",
    "        y[i, :, 0] = np.cos(freq * t + phase)  # Predict derivative\n",
    "    \n",
    "    return mx.array(X), mx.array(y)\n",
    "\n",
    "# Generate data\n",
    "X_train, y_train = create_sine_data()\n",
    "X_test, y_test = create_sine_data(samples=100)\n",
    "\n",
    "# Create models with different wirings\n",
    "models = {\n",
    "    'Fully Connected': CfC(FullyConnected(32, output_dim=1)),\n",
    "    'Random Sparse': CfC(Random(32, output_dim=1, sparsity_level=0.5)),\n",
    "    'NCP': CfC(AutoNCP(32, output_size=1, sparsity_level=0.5))\n",
    "}\n",
    "\n",
    "# Training function\n",
    "def train_model(model, X, y, epochs=100):\n",
    "    optimizer = nn.Adam(learning_rate=0.001)\n",
    "    losses = []\n",
    "    \n",
    "    def loss_fn(model, x, y):\n",
    "        pred = model(x)\n",
    "        return mx.mean((pred - y) ** 2)\n",
    "    \n",
    "    loss_and_grad = nn.value_and_grad(model, loss_fn)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss, grads = loss_and_grad(model, X, y)\n",
    "        optimizer.update(model, grads)\n",
    "        losses.append(float(loss))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {float(loss):.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Train and compare models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    losses = train_model(model, X_train, y_train)\n",
    "    results[name] = losses\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, losses in results.items():\n",
    "    plt.plot(losses, label=name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss by Wiring Pattern')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Different wiring patterns have different strengths:\n",
    "\n",
    "1. **Fully Connected**\n",
    "   - Maximum expressivity\n",
    "   - Higher memory usage\n",
    "   - May overfit on small datasets\n",
    "\n",
    "2. **Random Sparse**\n",
    "   - Better generalization\n",
    "   - More efficient\n",
    "   - May miss important connections\n",
    "\n",
    "3. **NCP**\n",
    "   - Structured connectivity\n",
    "   - Good balance of efficiency and performance\n",
    "   - Inspired by biological neural circuits\n",
    "\n",
    "Choose the wiring pattern based on your specific needs:\n",
    "- Use fully connected for small networks where expressivity is key\n",
    "- Use random sparse for large networks where efficiency matters\n",
    "- Use NCP for structured problems with clear hierarchies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
