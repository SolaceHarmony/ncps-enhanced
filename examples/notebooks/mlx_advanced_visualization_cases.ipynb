{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Visualization Use Cases\n",
    "\n",
    "This notebook demonstrates advanced visualization techniques for specific use cases:\n",
    "- Time Series Analysis\n",
    "- Reinforcement Learning\n",
    "- Anomaly Detection\n",
    "- Real-time Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ncps.mlx import CfC, LTC\n",
    "from ncps.mlx.wirings import Random, NCP, AutoNCP\n",
    "from ncps.mlx.advanced_profiling import MLXProfiler\n",
    "from ncps.mlx.visualization import WiringVisualizer, PerformanceVisualizer, ProfileVisualizer, plot_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Analysis\n",
    "\n",
    "Visualize temporal patterns and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_temporal_patterns(model, data, targets):\n",
    "    \"\"\"Analyze temporal patterns in predictions.\"\"\"\n",
    "    # Get predictions\n",
    "    preds = model(data)\n",
    "    \n",
    "    # Plot temporal patterns\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot example sequence\n",
    "    plt.subplot(221)\n",
    "    seq_idx = 0\n",
    "    plt.plot(data[seq_idx, :, 0], label='Input')\n",
    "    plt.plot(targets[seq_idx, :, 0], label='Target')\n",
    "    plt.plot(preds[seq_idx, :, 0], label='Prediction')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Example Sequence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot prediction error over time\n",
    "    plt.subplot(222)\n",
    "    error = mx.mean((preds - targets) ** 2, axis=2)\n",
    "    plt.plot(mx.mean(error, axis=0))\n",
    "    plt.fill_between(\n",
    "        range(error.shape[1]),\n",
    "        mx.mean(error, axis=0) - mx.std(error, axis=0),\n",
    "        mx.mean(error, axis=0) + mx.std(error, axis=0),\n",
    "        alpha=0.3\n",
    "    )\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Prediction Error Over Time')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot attention heatmap\n",
    "    plt.subplot(223)\n",
    "    attention = mx.abs(model.cell.wiring.adjacency_matrix)\n",
    "    plt.imshow(attention, cmap='viridis')\n",
    "    plt.colorbar(label='Connection Strength')\n",
    "    plt.xlabel('To Node')\n",
    "    plt.ylabel('From Node')\n",
    "    plt.title('Temporal Attention')\n",
    "    \n",
    "    # Plot frequency response\n",
    "    plt.subplot(224)\n",
    "    freqs = np.fft.fftfreq(data.shape[1])\n",
    "    input_fft = np.abs(np.fft.fft(data[0, :, 0]))\n",
    "    pred_fft = np.abs(np.fft.fft(preds[0, :, 0]))\n",
    "    plt.plot(freqs[1:len(freqs)//2], input_fft[1:len(freqs)//2], label='Input')\n",
    "    plt.plot(freqs[1:len(freqs)//2], pred_fft[1:len(freqs)//2], label='Prediction')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.title('Frequency Response')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate time series data\n",
    "def generate_time_series(n_samples=1000, seq_length=50):\n",
    "    t = np.linspace(0, 4*np.pi, seq_length)\n",
    "    X = np.zeros((n_samples, seq_length, 1))\n",
    "    y = np.zeros((n_samples, seq_length, 1))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        freq = 1.0 + 0.1 * np.random.randn()\n",
    "        phase = 2 * np.pi * np.random.rand()\n",
    "        X[i, :, 0] = np.sin(freq * t + phase)\n",
    "        y[i, :, 0] = np.cos(freq * t + phase)\n",
    "    \n",
    "    return mx.array(X), mx.array(y)\n",
    "\n",
    "# Create and train model\n",
    "X, y = generate_time_series()\n",
    "model = CfC(Random(units=100, sparsity_level=0.5))\n",
    "\n",
    "# Train model\n",
    "optimizer = nn.Adam(learning_rate=0.001)\n",
    "for epoch in range(50):\n",
    "    def loss_fn(model, x, y):\n",
    "        pred = model(x)\n",
    "        return mx.mean((pred - y) ** 2)\n",
    "    \n",
    "    loss, grads = mx.value_and_grad(model, loss_fn)(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "\n",
    "# Analyze temporal patterns\n",
    "analyze_temporal_patterns(model, X[:10], y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reinforcement Learning Analysis\n",
    "\n",
    "Visualize RL training dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_rl_dynamics(model, states, actions, rewards):\n",
    "    \"\"\"Analyze reinforcement learning dynamics.\"\"\"\n",
    "    # Get action predictions\n",
    "    pred_actions = model(states)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot state-action mapping\n",
    "    plt.subplot(221)\n",
    "    plt.scatter(states[:, 0, 0], states[:, 0, 1],\n",
    "                c=actions[:, 0, 0], cmap='viridis')\n",
    "    plt.colorbar(label='Action')\n",
    "    plt.xlabel('State Dim 1')\n",
    "    plt.ylabel('State Dim 2')\n",
    "    plt.title('State-Action Mapping')\n",
    "    \n",
    "    # Plot value function\n",
    "    plt.subplot(222)\n",
    "    plt.scatter(states[:, 0, 0], states[:, 0, 1],\n",
    "                c=rewards[:, 0], cmap='viridis')\n",
    "    plt.colorbar(label='Value')\n",
    "    plt.xlabel('State Dim 1')\n",
    "    plt.ylabel('State Dim 2')\n",
    "    plt.title('Value Function')\n",
    "    \n",
    "    # Plot action distribution\n",
    "    plt.subplot(223)\n",
    "    plt.hist2d(actions[:, 0, 0].reshape(-1),\n",
    "               pred_actions[:, 0, 0].reshape(-1),\n",
    "               bins=50)\n",
    "    plt.colorbar(label='Count')\n",
    "    plt.xlabel('True Action')\n",
    "    plt.ylabel('Predicted Action')\n",
    "    plt.title('Action Distribution')\n",
    "    \n",
    "    # Plot reward correlation\n",
    "    plt.subplot(224)\n",
    "    action_error = mx.mean((pred_actions - actions) ** 2, axis=2)\n",
    "    plt.scatter(rewards[:, 0], action_error[:, 0], alpha=0.5)\n",
    "    plt.xlabel('Reward')\n",
    "    plt.ylabel('Action Error')\n",
    "    plt.title('Reward vs Action Error')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate RL data\n",
    "def generate_rl_data(n_samples=1000, seq_length=10):\n",
    "    states = np.random.randn(n_samples, seq_length, 2)\n",
    "    actions = np.random.randn(n_samples, seq_length, 1)\n",
    "    rewards = np.sum(states ** 2, axis=2)\n",
    "    return mx.array(states), mx.array(actions), mx.array(rewards)\n",
    "\n",
    "# Create and train model\n",
    "states, actions, rewards = generate_rl_data()\n",
    "model = CfC(NCP(\n",
    "    inter_neurons=50,\n",
    "    command_neurons=30,\n",
    "    motor_neurons=1,\n",
    "    sensory_fanout=3,\n",
    "    inter_fanout=3,\n",
    "    recurrent_command_synapses=5,\n",
    "    motor_fanin=3\n",
    "))\n",
    "\n",
    "# Train model\n",
    "optimizer = nn.Adam(learning_rate=0.001)\n",
    "for epoch in range(50):\n",
    "    def loss_fn(model, x, y):\n",
    "        pred = model(x)\n",
    "        return mx.mean((pred - y) ** 2)\n",
    "    \n",
    "    loss, grads = mx.value_and_grad(model, loss_fn)(model, states, actions)\n",
    "    optimizer.update(model, grads)\n",
    "\n",
    "# Analyze RL dynamics\n",
    "analyze_rl_dynamics(model, states, actions, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection\n",
    "\n",
    "Visualize anomaly detection patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_anomalies(model, data, anomaly_scores):\n",
    "    \"\"\"Analyze anomaly detection patterns.\"\"\"\n",
    "    # Get reconstructions\n",
    "    reconstructions = model(data)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot normal vs anomalous patterns\n",
    "    plt.subplot(221)\n",
    "    normal_idx = np.argmin(anomaly_scores)\n",
    "    anomaly_idx = np.argmax(anomaly_scores)\n",
    "    plt.plot(data[normal_idx, :, 0], label='Normal')\n",
    "    plt.plot(data[anomaly_idx, :, 0], label='Anomaly')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Normal vs Anomalous Patterns')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot reconstruction error distribution\n",
    "    plt.subplot(222)\n",
    "    error = mx.mean((reconstructions - data) ** 2, axis=(1, 2))\n",
    "    plt.hist(error, bins=50, density=True, alpha=0.7)\n",
    "    plt.axvline(error[anomaly_idx], color='r', linestyle='--',\n",
    "                label='Max Anomaly')\n",
    "    plt.xlabel('Reconstruction Error')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Error Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot temporal anomaly scores\n",
    "    plt.subplot(223)\n",
    "    temporal_error = mx.mean((reconstructions - data) ** 2, axis=2)\n",
    "    plt.imshow(temporal_error.T, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Error')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Time Step')\n",
    "    plt.title('Temporal Anomaly Scores')\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.subplot(224)\n",
    "    feature_error = mx.mean((reconstructions - data) ** 2, axis=1)\n",
    "    plt.boxplot([feature_error[:, i] for i in range(feature_error.shape[1])])\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Reconstruction Error')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate anomaly data\n",
    "def generate_anomaly_data(n_samples=1000, seq_length=50, n_features=3):\n",
    "    data = np.random.randn(n_samples, seq_length, n_features)\n",
    "    # Add anomalies\n",
    "    anomaly_idx = np.random.choice(n_samples, size=int(0.1*n_samples))\n",
    "    data[anomaly_idx] += 3 * np.random.randn(len(anomaly_idx), seq_length, n_features)\n",
    "    # Calculate anomaly scores\n",
    "    anomaly_scores = np.mean(data ** 2, axis=(1, 2))\n",
    "    return mx.array(data), mx.array(anomaly_scores)\n",
    "\n",
    "# Create and train model\n",
    "data, anomaly_scores = generate_anomaly_data()\n",
    "model = CfC(AutoNCP(units=100, output_size=3, sparsity_level=0.5))\n",
    "\n",
    "# Train model\n",
    "optimizer = nn.Adam(learning_rate=0.001)\n",
    "for epoch in range(50):\n",
    "    def loss_fn(model, x):\n",
    "        pred = model(x)\n",
    "        return mx.mean((pred - x) ** 2)\n",
    "    \n",
    "    loss, grads = mx.value_and_grad(model, loss_fn)(model, data)\n",
    "    optimizer.update(model, grads)\n",
    "\n",
    "# Analyze anomalies\n",
    "analyze_anomalies(model, data, anomaly_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-time Control\n",
    "\n",
    "Visualize control system behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_control_system(model, states, actions, targets):\n",
    "    \"\"\"Analyze control system behavior.\"\"\"\n",
    "    # Get control signals\n",
    "    pred_actions = model(states)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot trajectory\n",
    "    plt.subplot(221)\n",
    "    plt.plot(states[0, :, 0], states[0, :, 1], label='Actual')\n",
    "    plt.plot(targets[0, :, 0], targets[0, :, 1], '--', label='Target')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title('System Trajectory')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot control signals\n",
    "    plt.subplot(222)\n",
    "    plt.plot(actions[0, :, 0], label='True Control')\n",
    "    plt.plot(pred_actions[0, :, 0], '--', label='Predicted Control')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Control Signal')\n",
    "    plt.title('Control Signals')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot phase portrait\n",
    "    plt.subplot(223)\n",
    "    plt.quiver(states[0, :-1, 0], states[0, :-1, 1],\n",
    "               states[0, 1:, 0] - states[0, :-1, 0],\n",
    "               states[0, 1:, 1] - states[0, :-1, 1])\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title('Phase Portrait')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot error over time\n",
    "    plt.subplot(224)\n",
    "    error = mx.sqrt(mx.sum((states - targets) ** 2, axis=2))\n",
    "    plt.plot(mx.mean(error, axis=0))\n",
    "    plt.fill_between(\n",
    "        range(error.shape[1]),\n",
    "        mx.mean(error, axis=0) - mx.std(error, axis=0),\n",
    "        mx.mean(error, axis=0) + mx.std(error, axis=0),\n",
    "        alpha=0.3\n",
    "    )\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Tracking Error')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate control data\n",
    "def generate_control_data(n_samples=1000, seq_length=50):\n",
    "    t = np.linspace(0, 2*np.pi, seq_length)\n",
    "    states = np.zeros((n_samples, seq_length, 4))  # [x, y, vx, vy]\n",
    "    actions = np.zeros((n_samples, seq_length, 2))  # [ax, ay]\n",
    "    targets = np.zeros((n_samples, seq_length, 2))  # [x, y]\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        radius = 1.0 + 0.1 * np.random.randn()\n",
    "        phase = 2 * np.pi * np.random.rand()\n",
    "        \n",
    "        # Target trajectory\n",
    "        targets[i, :, 0] = radius * np.cos(t + phase)\n",
    "        targets[i, :, 1] = radius * np.sin(t + phase)\n",
    "        \n",
    "        # State trajectory with noise\n",
    "        states[i, :, 0] = targets[i, :, 0] + 0.1 * np.random.randn(seq_length)\n",
    "        states[i, :, 1] = targets[i, :, 1] + 0.1 * np.random.randn(seq_length)\n",
    "        states[i, :, 2] = np.gradient(states[i, :, 0], t)\n",
    "        states[i, :, 3] = np.gradient(states[i, :, 1], t)\n",
    "        \n",
    "        # Control actions\n",
    "        actions[i, :, 0] = np.gradient(states[i, :, 2], t)\n",
    "        actions[i, :, 1] = np.gradient(states[i, :, 3], t)\n",
    "    \n",
    "    return mx.array(states), mx.array(actions), mx.array(targets)\n",
    "\n",
    "# Create and train model\n",
    "states, actions, targets = generate_control_data()\n",
    "model = CfC(NCP(\n",
    "    inter_neurons=50,\n",
    "    command_neurons=30,\n",
    "    motor_neurons=2,\n",
    "    sensory_fanout=3,\n",
    "    inter_fanout=3,\n",
    "    recurrent_command_synapses=5,\n",
    "    motor_fanin=3\n",
    "))\n",
    "\n",
    "# Train model\n",
    "optimizer = nn.Adam(learning_rate=0.001)\n",
    "for epoch in range(50):\n",
    "    def loss_fn(model, x, y):\n",
    "        pred = model(x)\n",
    "        return mx.mean((pred - y) ** 2)\n",
    "    \n",
    "    loss, grads = mx.value_and_grad(model, loss_fn)(model, states, actions)\n",
    "    optimizer.update(model, grads)\n",
    "\n",
    "# Analyze control system\n",
    "analyze_control_system(model, states, actions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Insights\n",
    "\n",
    "Based on our analysis:\n",
    "\n",
    "1. **Time Series**\n",
    "   - Strong temporal dependencies\n",
    "   - Good prediction accuracy\n",
    "   - Clear frequency patterns\n",
    "\n",
    "2. **Reinforcement Learning**\n",
    "   - State-action mapping learned\n",
    "   - Value function approximated\n",
    "   - Action distribution matched\n",
    "\n",
    "3. **Anomaly Detection**\n",
    "   - Clear anomaly patterns\n",
    "   - Good reconstruction\n",
    "   - Feature importance identified\n",
    "\n",
    "4. **Control Systems**\n",
    "   - Stable tracking\n",
    "   - Smooth control signals\n",
    "   - Error convergence\n",
    "\n",
    "Recommendations:\n",
    "- Use task-specific visualizations\n",
    "- Monitor multiple aspects\n",
    "- Analyze temporal patterns\n",
    "- Track system behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
