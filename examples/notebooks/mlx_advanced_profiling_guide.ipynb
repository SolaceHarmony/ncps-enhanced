{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Profiling Guide for Neural Circuit Policies\n",
    "\n",
    "This notebook demonstrates how to use advanced profiling tools with MLX integration:\n",
    "- Compute profiling\n",
    "- Memory profiling\n",
    "- Stream profiling\n",
    "- Performance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ncps.mlx import CfC, LTC\n",
    "from ncps.mlx.wirings import Random, NCP, AutoNCP\n",
    "from ncps.mlx.advanced_profiling import MLXProfiler, quick_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Profiling\n",
    "\n",
    "Let's start with a quick overview of model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "wiring = Random(units=100, sparsity_level=0.5)\n",
    "model = CfC(wiring=wiring)\n",
    "\n",
    "# Quick profile\n",
    "stats = quick_profile(\n",
    "    model,\n",
    "    batch_size=32,\n",
    "    seq_length=10,\n",
    "    num_runs=100\n",
    ")\n",
    "\n",
    "print(\"Compute Performance:\")\n",
    "for key, value in stats['compute'].items():\n",
    "    if 'time' in key:\n",
    "        print(f\"{key}: {value*1000:.2f} ms\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nMemory Usage:\")\n",
    "for key, value in stats['memory'].items():\n",
    "    print(f\"{key}: {value:.2f} MB\")\n",
    "\n",
    "print(\"\\nStream Operations:\")\n",
    "for key, value in stats['stream'].items():\n",
    "    if 'time' in key:\n",
    "        print(f\"{key}: {value*1000:.2f} ms\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detailed Compute Analysis\n",
    "\n",
    "Let's analyze computational performance in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create profiler\n",
    "profiler = MLXProfiler(model)\n",
    "\n",
    "# Profile different batch sizes\n",
    "batch_sizes = [1, 16, 32, 64, 128]\n",
    "compute_results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    stats = profiler.profile_compute(\n",
    "        batch_size=batch_size,\n",
    "        seq_length=10,\n",
    "        num_runs=50\n",
    "    )\n",
    "    compute_results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'time': stats['time_mean'],\n",
    "        'tflops': stats['tflops']\n",
    "    })\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot([r['batch_size'] for r in compute_results],\n",
    "         [r['time']*1000 for r in compute_results],\n",
    "         marker='o')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Compute Time vs Batch Size')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot([r['batch_size'] for r in compute_results],\n",
    "         [r['tflops'] for r in compute_results],\n",
    "         marker='o')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('TFLOPS')\n",
    "plt.title('Compute Efficiency vs Batch Size')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory Analysis\n",
    "\n",
    "Let's examine memory usage patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_memory_scaling(sizes=[50, 100, 200, 400]):\n",
    "    \"\"\"Analyze memory scaling with network size.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Create model\n",
    "        wiring = Random(units=size, sparsity_level=0.5)\n",
    "        model = CfC(wiring=wiring)\n",
    "        profiler = MLXProfiler(model)\n",
    "        \n",
    "        # Profile memory\n",
    "        stats = profiler.profile_memory(\n",
    "            batch_size=32,\n",
    "            seq_length=10\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'size': size,\n",
    "            'peak': stats['peak_usage'],\n",
    "            'allocated': stats['total_allocated']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze memory scaling\n",
    "memory_results = analyze_memory_scaling()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot([r['size'] for r in memory_results],\n",
    "         [r['peak'] for r in memory_results],\n",
    "         marker='o')\n",
    "plt.xlabel('Network Size')\n",
    "plt.ylabel('Peak Memory (MB)')\n",
    "plt.title('Peak Memory Usage')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot([r['size'] for r in memory_results],\n",
    "         [r['allocated'] for r in memory_results],\n",
    "         marker='o')\n",
    "plt.xlabel('Network Size')\n",
    "plt.ylabel('Total Allocated (MB)')\n",
    "plt.title('Total Memory Allocated')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stream Analysis\n",
    "\n",
    "Let's analyze stream operations and data transfers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stream_operations(seq_lengths=[10, 20, 50, 100]):\n",
    "    \"\"\"Analyze stream operations with different sequence lengths.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for seq_length in seq_lengths:\n",
    "        stats = profiler.profile_stream(\n",
    "            batch_size=32,\n",
    "            seq_length=seq_length\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'seq_length': seq_length,\n",
    "            'kernel_time': stats['kernel_time'],\n",
    "            'memory_time': stats['memory_time'],\n",
    "            'num_kernels': stats['num_kernels']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze stream operations\n",
    "stream_results = analyze_stream_operations()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot([r['seq_length'] for r in stream_results],\n",
    "         [r['kernel_time']*1000 for r in stream_results],\n",
    "         marker='o',\n",
    "         label='Kernel Time')\n",
    "plt.plot([r['seq_length'] for r in stream_results],\n",
    "         [r['memory_time']*1000 for r in stream_results],\n",
    "         marker='o',\n",
    "         label='Memory Time')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Operation Times')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot([r['seq_length'] for r in stream_results],\n",
    "         [r['num_kernels'] for r in stream_results],\n",
    "         marker='o')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Number of Kernels')\n",
    "plt.title('Kernel Count')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Optimization\n",
    "\n",
    "Let's compare different wiring patterns and configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_wirings():\n",
    "    \"\"\"Compare different wiring patterns.\"\"\"\n",
    "    configs = [\n",
    "        ('Random Dense', Random(units=100, sparsity_level=0.2)),\n",
    "        ('Random Sparse', Random(units=100, sparsity_level=0.8)),\n",
    "        ('NCP', NCP(\n",
    "            inter_neurons=50,\n",
    "            command_neurons=30,\n",
    "            motor_neurons=20,\n",
    "            sensory_fanout=5,\n",
    "            inter_fanout=5,\n",
    "            recurrent_command_synapses=10,\n",
    "            motor_fanin=5\n",
    "        )),\n",
    "        ('AutoNCP', AutoNCP(units=100, output_size=20, sparsity_level=0.5))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for name, wiring in configs:\n",
    "        model = CfC(wiring=wiring)\n",
    "        stats = quick_profile(model)\n",
    "        \n",
    "        results.append({\n",
    "            'name': name,\n",
    "            'compute_time': stats['compute']['time_mean'],\n",
    "            'memory_usage': stats['memory']['peak_usage'],\n",
    "            'tflops': stats['compute']['tflops']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare wiring patterns\n",
    "comparison_results = compare_wirings()\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar([r['name'] for r in comparison_results],\n",
    "        [r['compute_time']*1000 for r in comparison_results])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Compute Time (ms)')\n",
    "plt.title('Computation Time')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.bar([r['name'] for r in comparison_results],\n",
    "        [r['memory_usage'] for r in comparison_results])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "plt.title('Memory Usage')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.bar([r['name'] for r in comparison_results],\n",
    "        [r['tflops'] for r in comparison_results])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('TFLOPS')\n",
    "plt.title('Compute Efficiency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Insights\n",
    "\n",
    "Based on our analysis:\n",
    "\n",
    "1. **Compute Performance**\n",
    "   - Larger batch sizes improve TFLOPS\n",
    "   - Dense patterns are faster for small networks\n",
    "   - Sparse patterns scale better\n",
    "\n",
    "2. **Memory Usage**\n",
    "   - Memory scales quadratically with size\n",
    "   - Sparsity significantly reduces memory\n",
    "   - AutoNCP provides good balance\n",
    "\n",
    "3. **Stream Operations**\n",
    "   - Kernel time dominates for large sequences\n",
    "   - Memory transfers increase with size\n",
    "   - Batch processing helps efficiency\n",
    "\n",
    "4. **Optimization Tips**\n",
    "   - Choose sparsity based on size\n",
    "   - Optimize batch size for hardware\n",
    "   - Consider sequence length impact\n",
    "   - Monitor memory allocation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
