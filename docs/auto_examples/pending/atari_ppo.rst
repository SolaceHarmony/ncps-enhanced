
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/atari_ppo.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_atari_ppo.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_atari_ppo.py:


PPO Implementation of Neural Circuit Policies for Atari Games

This example demonstrates how to use NCPs with Proximal Policy Optimization (PPO)
for training agents on Atari games. It showcases:
- Setting up an NCP model for Atari environments
- Implementing PPO training algorithm
- Performance monitoring and visualization

.. GENERATED FROM PYTHON SOURCE LINES 10-18

.. code-block:: Python


    import torch
    import torch.nn as nn
    import numpy as np
    from ncps.torch import CfC

    # Rest of implementation will be handled by code mode
    pass

**Estimated memory usage:**  0 MB


.. _sphx_glr_download_auto_examples_atari_ppo.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: atari_ppo.ipynb <atari_ppo.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: atari_ppo.py <atari_ppo.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: atari_ppo.zip <atari_ppo.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
